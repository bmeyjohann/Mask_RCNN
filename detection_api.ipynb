{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IP adress of device capturing images.\n",
    "CAMERA_HOST = \"192.168.1.106\"\n",
    "# Port on which the server for capturing is listening.\n",
    "CAMERA_PORT = 1300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install Flask\n",
    "import json\n",
    "from flask import Flask, jsonify\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import importlib\n",
    "import skimage\n",
    "import json\n",
    "import wandb\n",
    "import socket\n",
    "import json\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Following lines were sometimes needed to be able to train on an Nvidia RTX 2060 super.\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True\n",
    "#sess = tf.Session(config=config)\n",
    "\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "#tf.keras.backend.set_session(tf.Session(config=config));\n",
    "\n",
    "# Right now, this line does the trick.\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "# See if GPU has been detected.\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"\")\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "importlib.reload(modellib)\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IEConfig(Config):\n",
    "    \"\"\"\n",
    "    Configuration for running inference.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to this project.\n",
    "    \"\"\"\n",
    "    NAME = \"InteractiveElements\"\n",
    "\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    CLASSES = [\"Menu\", \"BackButton\", \"MoreOptions\", \"FloatingActionButton\",\n",
    "               \"NavigationBarItem\", \"Button\", \"Checkbox\", \"RadioButton\", \"Switch\", \"Slider\", \"TextField\"]\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + len(CLASSES)\n",
    "\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(IEConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Create the model in inference mode.\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights.\n",
    "# Either set a specific path or find last trained weights.\n",
    "model_path = os.path.join(ROOT_DIR, \"logs/interactiveelements20221204T0029/mask_rcnn_interactiveelements_0060.h5\")\n",
    "# model_path = model.find_last()\n",
    "\n",
    "# Load trained weights.\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageFromServer():\n",
    "    for i in range(100):\n",
    "        try:\n",
    "            client = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "            client.settimeout(1)\n",
    "\n",
    "            client.connect((CAMERA_HOST, CAMERA_PORT))\n",
    "            request = {\"header\": \"raw\"}\n",
    "            client.sendall((json.dumps(request) + \"\\n\").encode())\n",
    "            image_base64 = client.makefile().readline()\n",
    "            image_bytes = base64.b64decode(image_base64)\n",
    "            image_file = BytesIO(image_bytes)\n",
    "            image = Image.open(image_file)\n",
    "            return image\n",
    "        except:\n",
    "            print(\"Connection refused:\", i, \"/\", 100)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [09/Dec/2022 10:14:52] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Dec/2022 10:14:52] \"HEAD / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "@app.route('/')\n",
    "def detection():\n",
    "    image = getImageFromServer()\n",
    "    image = np.array(image)\n",
    "    \n",
    "    r = model.detect([image], verbose=0)[0]\n",
    "    clear_output(wait=True)\n",
    "    visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                                dataset_val.class_names, r['scores'], figsize=(16, 16))\n",
    "    return jsonify(r)\n",
    "\n",
    "app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7dfe93aa6be5f5bb1484b98a95bf4dd6932b1152ab46015ab33ed30abda949f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
